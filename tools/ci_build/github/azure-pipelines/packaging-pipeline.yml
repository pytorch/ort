stages:
- stage: Python_Packaging

  jobs:
    - job: Linux_py_GPU_Wheels
      timeoutInMinutes: 180
      workspace:
        clean: all
      pool: Onnxruntime-Linux-GPU
      strategy:
        matrix:
          Python38 Cuda10.2 TorchAndOrtNightly:
            PythonVersion: '3.8'
            PublicDockerFile: 'docker/Dockerfile.torch-and-ort-nightly-cu102-cudnn7-devel-ubuntu18.04'
          Python38 Cuda11.1 TorchAndOrtNightly:
            PythonVersion: '3.8'
            PublicDockerFile: 'docker/Dockerfile.torch-and-ort-nightly-cu111-cudnn8-devel-ubuntu18.04'
          Python38 Cuda10.2 OrtNightly:
            PythonVersion: '3.8'
            PublicDockerFile: 'docker/Dockerfile.ort-nightly-cu102-cudnn7-devel-ubuntu18.04'
          Python38 Cuda11.1 OrtNightly:
            PythonVersion: '3.8'
            PublicDockerFile: 'docker/Dockerfile.ort-nightly-cu111-cudnn8-devel-ubuntu18.04'
            UploadWheel: 'yes'
          Python38 Cuda10.2 Stable:
            PythonVersion: '3.8'
            PublicDockerFile: 'docker/Dockerfile.ort-cu102-cudnn7-devel-ubuntu18.04'
          Python38 Cuda11.1 Stable:
            PythonVersion: '3.8'
            PublicDockerFile: 'docker/Dockerfile.ort-cu111-cudnn8-devel-ubuntu18.04'

      steps:
      - checkout: self
        clean: true
        submodules: recursive

      - template: templates/set-python-manylinux-variables-step.yml

      - template: templates/get-docker-image-steps.yml
        parameters:
          # torch-ort is device neutral, we just pick randomely cuda11.1
          Dockerfile: tools/ci_build/github/linux/docker/Dockerfile.manylinux2014_cuda11_1
          Context: tools/ci_build/github/linux/docker
          DockerBuildArgs: >-
            --build-arg PYTHON_VERSION=$(PythonVersion)
            --build-arg BUILD_UID=$(id -u)
          Repository: torchortpackaging

      # TODO: because the docker image (torchortpackaging) is cached,
      # it may keep failing if the onnxruntime-training or torch installation
      # that are cached with the image is causing the failure. 
      # in such case, we need to clearn the cache (onnxruntimebuildcache) 
      - task: CmdLine@2
        inputs:
          script: |
            docker run --rm --gpus all \
              --volume $(Build.SourcesDirectory):/torch_ort_src \
              -e NVIDIA_VISIBLE_DEVICES=all \
              -e NIGHTLY_BUILD \
              -e BUILD_BUILDNUMBER \
              -w /torch_ort_src \
              torchortpackaging \
                $(PythonManylinuxDir)/bin/python3 build.py
          workingDirectory: $(Build.SourcesDirectory)

      - task: CopyFiles@2
        displayName: 'Copy Python Wheel to: $(Build.ArtifactStagingDirectory)'
        inputs:
          SourceFolder: '$(Build.SourcesDirectory)'
          Contents: 'dist/*.whl'
          TargetFolder: '$(Build.ArtifactStagingDirectory)'

      - task: PublishBuildArtifacts@1
        displayName: 'Publish Artifact: torch-ort python wheel'
        inputs:
          ArtifactName: torch-ort

      # now we have wheel from manylinux, test it with public dockers
      - task: CmdLine@2
        inputs:
          script: |
            docker build -f $(PublicDockerFile) -t torchortpackagingtest .
        displayName: "docker build -f $(PublicDockerFile) -t torchortpackagingtest"

      # dockerfile has torch-ort. uninstall it to prepare for new install from current build
      - task: CmdLine@2
        inputs:
          script: |
            docker run \
              torchortpackagingtest \
                /usr/bin/python3 -m pip uninstall -y torch-ort
          workingDirectory: $(Build.SourcesDirectory)
        displayName: "uninstall torch-ort"

      - task: CmdLine@2
        inputs:
          script: |
            files=($(Build.SourcesDirectory)/dist/*.whl) && \
            echo ${files[0]} && \
            whlfilename=$(basename ${files[0]}) && \
            echo $whlfilename && \
            docker run --rm --gpus all \
              --volume $(Build.SourcesDirectory):/torch_ort_src \
              -w /torch_ort_src \
              torchortpackagingtest \
                /usr/bin/python3 build.py --wheel_file /torch_ort_src/dist/$whlfilename
          workingDirectory: $(Build.SourcesDirectory)
        displayName: "docker run build.py --wheel_file /torch_ort_src/dist/$whlfilename"

      - task: AzureCLI@2
        condition: and(succeeded(), eq(variables['UploadWheel'], 'yes'))
        inputs:
          azureSubscription: 'AIInfraBuildOnnxRuntimeOSS'
          scriptType: 'bash'
          scriptLocation: 'inlineScript'
          inlineScript: |
            python3 -m pip install azure-storage-blob==2.1.0 && \
            files=($(Build.SourcesDirectory)/dist/*.whl) && \
            echo ${files[0]} && \
            python3 tools/python/upload_python_package_to_azure_storage.py \
                --python_wheel_path ${files[0]} \
                --account_name onnxruntimepackages \
                --account_key $(orttrainingpackagestorageaccountkey) \
                --container_name '$web'
          displayName: "upload to nightly package channel"

      - template: templates/component-governance-component-detection-steps.yml
        parameters:
          condition: 'succeeded'

      - template: templates/clean-agent-build-directory-step.yml