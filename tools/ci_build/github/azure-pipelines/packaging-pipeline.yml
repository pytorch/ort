stages:
- stage: Python_Packaging

  jobs:
    - job: Linux_py_GPU_Wheels
      timeoutInMinutes: 180
      workspace:
        clean: all
      pool: Onnxruntime-Linux-GPU
      strategy:
        matrix:
          Python38 TorchAndOrtNightly Cuda10.2:
            PythonVersion: '3.8'
            PublicDockerFile: 'docker/Dockerfile.ort-torch-and-onnxruntime-nightly-cu102-cudnn7-devel-ubuntu18.04'
          Python38 TorchAndOrtNightly Cuda11.1:
            PythonVersion: '3.8'
            PublicDockerFile: 'docker/Dockerfile.ort-torch-and-onnxruntime-nightly-cu111-cudnn8-devel-ubuntu18.04'
          Python38 Torch181 onnxruntimeNightly Cuda10.2:
            PythonVersion: '3.8'
            PublicDockerFile: 'docker/Dockerfile.ort-torch181-onnxruntime-nightly-cu102-cudnn7-devel-ubuntu18.04'
          Python38 Torch181 onnxruntimeNightly Cuda11.1:
            PythonVersion: '3.8'
            PublicDockerFile: 'docker/Dockerfile.ort-torch181-onnxruntime-nightly-cu111-cudnn8-devel-ubuntu18.04'
          Python38 Torch190 onnxruntimeNightly Cuda10.2:
            PythonVersion: '3.8'
            PublicDockerFile: 'docker/Dockerfile.ort-torch190-onnxruntime-nightly-cu102-cudnn7-devel-ubuntu18.04'
          Python38 Torch190 onnxruntimeNightly Cuda11.1:
            PythonVersion: '3.8'
            PublicDockerFile: 'docker/Dockerfile.ort-torch190-onnxruntime-nightly-cu111-cudnn8-devel-ubuntu18.04'
          # TODO: Reenable torch ort stable pipelines.
          # Python38 Torch181 onxruntime181 Cuda10.2:
          #   PythonVersion: '3.8'
          #   PublicDockerFile: 'docker/Dockerfile.ort-torch181-onnxruntime181-cu102-cudnn7-devel-ubuntu18.04'
          # Python38 Torch181 onxruntime181 Cuda11.1:
          #   PythonVersion: '3.8'
          #   PublicDockerFile: 'docker/Dockerfile.ort-torch181-onnxruntime181-cu111-cudnn8-devel-ubuntu18.04'
          # Python38 Torch190 onxruntime181 Cuda10.2:
          #   PythonVersion: '3.8'
          #   PublicDockerFile: 'docker/Dockerfile.ort-torch190-onnxruntime181-cu102-cudnn7-devel-ubuntu18.04'
          # Python38 Torch190 onxruntime181 Cuda11.1:
          #   PythonVersion: '3.8'
          #   PublicDockerFile: 'docker/Dockerfile.ort-torch190-onnxruntime181-cu111-cudnn8-devel-ubuntu18.04'
          #   UploadWheel: 'yes'
          # Python38 Default Torch190 onxruntime181 Cuda11.1:
          #   PythonVersion: '3.8'
          #   PublicDockerFile: 'docker/Dockerfile.ort-default-stable-torch190-onnxruntime181-cu102-cudnn7-devel-ubuntu18.04'

      steps:
      - checkout: self
        clean: true
        submodules: recursive

      - template: templates/set-python-manylinux-variables-step.yml

      - template: templates/get-docker-image-steps.yml
        parameters:
          # torch-ort is device neutral, we just pick randomly cuda11.1
          Dockerfile: tools/ci_build/github/linux/docker/Dockerfile.manylinux2014_cuda11_1
          Context: tools/ci_build/github/linux/docker
          DockerBuildArgs: >-
            --build-arg PYTHON_VERSION=$(PythonVersion)
            --build-arg BUILD_UID=$(id -u)
          Repository: torchortpackaging

      # TODO: because the docker image (torchortpackaging) is cached,
      # it may keep failing if the onnxruntime-training or torch installation
      # that are cached with the image is causing the failure.
      # in such case, we need to clean the cache (onnxruntimebuildcache)
      - task: CmdLine@2
        inputs:
          script: |
            docker run --rm --gpus all \
              --volume $(Build.SourcesDirectory):/torch_ort_src \
              -e NVIDIA_VISIBLE_DEVICES=all \
              -e NIGHTLY_BUILD \
              -e BUILD_BUILDNUMBER \
              -w /torch_ort_src \
              torchortpackaging \
                $(PythonManylinuxDir)/bin/python3 build.py
          workingDirectory: $(Build.SourcesDirectory)

      - task: CopyFiles@2
        condition: and(succeeded(), eq(variables['UploadWheel'], 'yes'))
        displayName: 'Copy Python Wheel to: $(Build.ArtifactStagingDirectory)'
        inputs:
          SourceFolder: '$(Build.SourcesDirectory)'
          Contents: 'dist/*.whl'
          TargetFolder: '$(Build.ArtifactStagingDirectory)'

      - task: PublishBuildArtifacts@1
        displayName: 'Publish Artifact: torch-ort python wheel'
        inputs:
          ArtifactName: torch-ort

      # now we have wheel from manylinux, test it with public dockers
      - task: CmdLine@2
        inputs:
          script: |
            docker build -f $(PublicDockerFile) -t torchortpackagingtest .
        displayName: "docker build -f $(PublicDockerFile) -t torchortpackagingtest"

      - task: CmdLine@2
        inputs:
          script: |
            files=($(Build.SourcesDirectory)/dist/*.whl) && \
            echo ${files[0]} && \
            whlfilename=$(basename ${files[0]}) && \
            echo $whlfilename && \
            docker run --rm --gpus all \
              --volume $(Build.SourcesDirectory):/torch_ort_src \
              -w /torch_ort_src \
              torchortpackagingtest \
                /usr/bin/python3 build.py --wheel_file /torch_ort_src/dist/$whlfilename
          workingDirectory: $(Build.SourcesDirectory)
        displayName: "docker run build.py --wheel_file /torch_ort_src/dist/$whlfilename"

      - task: AzureCLI@2
        condition: and(succeeded(), eq(variables['UploadWheel'], 'yes'))
        inputs:
          azureSubscription: 'AIInfraBuildOnnxRuntimeOSS'
          scriptType: 'bash'
          scriptLocation: 'inlineScript'
          inlineScript: |
            python3 -m pip install azure-storage-blob==2.1.0 && \
            files=($(Build.SourcesDirectory)/dist/*.whl) && \
            echo ${files[0]} && \
            python3 tools/python/upload_python_package_to_azure_storage.py \
                --python_wheel_path ${files[0]} \
                --account_name onnxruntimepackages \
                --account_key $(orttrainingpackagestorageaccountkey) \
                --container_name '$web'
          displayName: "upload to nightly package channel"

      - template: templates/component-governance-component-detection-steps.yml
        parameters:
          condition: 'succeeded'

      - template: templates/clean-agent-build-directory-step.yml